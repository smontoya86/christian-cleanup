llm_config = {
    "default": "ollama",
    "providers": {
        "ollama": {
            "api_base": "http://localhost:11434/v1",
            "model": "qwen2.5:0.5b"
        }
    }
}
